# Ejercicio de Integraci√≥n de ChatBot para Smarttie

Este proyecto tiene como objetivo integrar un chatbot inteligente para la empresa **Smarttie**. El chatbot est√° dise√±ado para interactuar con los usuarios de manera efectiva utilizando un modelo de lenguaje basado en **LLaMa 3.2-1B-Instruct**.

El chatbot puede responder preguntas, generar respuestas y almacenar el historial de la conversaci√≥n para mejorar la interacci√≥n. Adem√°s, tiene un dise√±o intuitivo creado con la biblioteca **Gradio**.

## Requisitos

Para ejecutar este proyecto, necesitar√°s instalar las siguientes dependencias:

- Python 3.7 o superior
- PyTorch (con soporte para CUDA)
- Hugging Face Transformers
- Gradio
- dotenv

## Instalaci√≥n

1. **Clona este repositorio** o descarga los archivos del proyecto.

   ```bash
   git clone https://github.com/BeyondEternalDEV/Smarrtie_Ejercicio.git
   cd Smarrtie_Ejercicio
   ```

2. **Crea un entorno virtual** (opcional pero recomendado):

   ```bash
   python -m venv venv
   source venv/bin/activate  # En Linux/Mac
   venv\Scripts\activate     # En Windows
   ```

3. **Instala las dependencias necesarias**:

   ```bash
   pip install -r requirements.txt
   ```

   El archivo `requirements.txt` debe contener:

   ```
   torch
   transformers
   gradio
   python-dotenv
   ```

4. **Configura tus variables de entorno**:

   Aseg√∫rate de tener un archivo `.env` en el directorio ra√≠z del proyecto. Este archivo debe contener el token de acceso a tu Hugging Face.

   Ejemplo de archivo `.env`:

   ```
   HF_TOKEN = tu_clave_api
   ```

## Uso

1. **Ejecuta el chatbot**:

   Para iniciar el chatbot, simplemente ejecuta el siguiente comando:

   ```bash
   python app.py
   ```

   Esto iniciar√° la interfaz web de **Gradio** donde podr√°s interactuar con el chatbot.

2. **Interacci√≥n con el chatbot**:

   - Puedes escribir un mensaje en el campo de texto y presionar **Enter** o hacer clic en el √≠cono de flecha **"‚û°"** para enviar el mensaje.
   - El chatbot tiene una configuraci√≥n de tokens m√°ximos y temperatura que puedes ajustar para personalizar la generaci√≥n de texto.

3. **Configuraciones**:
   - **Indicaci√≥n del Sistema**: Define el comportamiento y el contexto del chatbot.
   - **Tokens m√°ximos**: Ajusta la cantidad m√°xima de tokens generados por respuesta.
   - **Temperatura**: Controla la creatividad de las respuestas (0.0 para respuestas m√°s conservadoras, 1.0 para respuestas m√°s creativas).

4. **Limpiar el chat**:
   Puedes limpiar el historial de la conversaci√≥n haciendo clic en el bot√≥n **üóë Limpiar Chat**.

## Tecnolog√≠a Utilizada

- **LLaMa 3.2-1B-Instruct**: Un modelo de lenguaje avanzado de Hugging Face utilizado para generar respuestas del chatbot.
- **Gradio**: Una biblioteca para crear interfaces de usuario interactivas y f√°ciles de usar.
- **Transformers**: La biblioteca de Hugging Face para modelos de lenguaje y procesamiento de texto.
- **PyTorch**: La biblioteca utilizada para ejecutar el modelo en la GPU (si est√° disponible).

## Licencia

Este proyecto est√° bajo la licencia **MIT**.

---

Si tienes alguna pregunta o necesitas soporte adicional, no dudes en abrir un **issue** en este repositorio o contactar al equipo de desarrollo.
```

### Pasos para usar este archivo:
1. **Clona el repositorio** o guarda este contenido en un archivo llamado `README.md` en la ra√≠z de tu proyecto.
2. Aseg√∫rate de tener un archivo `.env` en tu proyecto si necesitas configuraciones adicionales como claves de API.
3. Sigue las instrucciones de instalaci√≥n y ejecuci√≥n que est√°n en el `README.md`.
